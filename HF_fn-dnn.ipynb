{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prepare and FC_DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UAvZxk4e9KOR"
   },
   "outputs": [],
   "source": [
    "# Import data_prepare modul that contains functions that we created.\n",
    "from data_prepare import *\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, Conv1D, MaxPooling1D, Dropout\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from scripts.reconstruction_minimal import createAudio\n",
    "import scipy.io.wavfile as wavfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0ZuYd79QvvG"
   },
   "source": [
    "# Prepare data for learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prepare the data for learning neural networks. We use a function that execute the results of the last milestone get a train-ready dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_datasets(pt, feat_path=r'./features'):\n",
    "    \n",
    "    r\"\"\"\n",
    "    Generate train and test datasets from the one sample of the raw data.\n",
    "    param pt: name of the sample\n",
    "    param feat_path: path of the raw data file\n",
    "  \"\"\"\n",
    "    \n",
    "    output = np.load(os.path.join(feat_path,f'{pt}_spec.npy'))\n",
    "    input = np.load(os.path.join(feat_path,f'{pt}_feat.npy'))\n",
    "    \n",
    "    # Reduce Dimensions\n",
    "    pca = PCA()\n",
    "    pca.fit(input)\n",
    "    input = np.dot(input, pca.components_[:50,:].T)\n",
    "\n",
    "    # Generate train, validation and test datasets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(input, output, test_size=0.1, shuffle=False)\n",
    "\n",
    "    shape1 = X_train.shape[1]\n",
    "    train = np.hstack((X_train, Y_train))\n",
    "    print(type(train))\n",
    "    print(train.shape)\n",
    "    print(shape1)\n",
    "    train = np.random.shuffle(train)\n",
    "    X_train = train[:, :shape1]\n",
    "    Y_train = train[:, shape1:]\n",
    "    \n",
    "    # Standardize input\n",
    "    mu_input = np.mean(X_train, axis=0)\n",
    "    std_input = np.std(X_train, axis=0)\n",
    "    X_train = (X_train-mu_input)/std_input\n",
    "    X_test = (X_test-mu_input)/std_input\n",
    "\n",
    "    # Standardize output\n",
    "    mu_output = np.mean(Y_train, axis=0)\n",
    "    std_output = np.std(Y_train, axis=0)\n",
    "    Y_train = (Y_train-mu_output)/std_output\n",
    "    Y_test = (Y_test-mu_output)/std_output\n",
    "\n",
    "\n",
    "    return (X_train, Y_train, X_test, Y_test, mu_input, std_input, mu_output, std_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_merged_dataset():\n",
    "    norm_params = {}\n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "    pts = ['sub-%02d'%i for i in range(1,11)]\n",
    "    (X_train, Y_train, x_test, y_test, mu_input, std_input, mu_output, std_output) = generate_datasets(pts[0])\n",
    "    norm_params[str(0)]={'mu_input':mu_input, 'std_input':std_input, 'mu_output':mu_output, 'std_output':std_output}\n",
    "    X_test.append(x_test)\n",
    "    Y_test.append(y_test)\n",
    "    for i, pt in enumerate(pts[1:]):\n",
    "        (x_train, y_train, x_test, y_test, mu_input, std_input, mu_output, std_output) = generate_datasets(pt)\n",
    "        norm_params[str(i+1)]={'mu_input':mu_input, 'std_input':std_input, 'mu_output':mu_output, 'std_output':std_output}\n",
    "        X_train = np.concatenate((X_train, x_train))\n",
    "        Y_train = np.concatenate((Y_train, y_train))\n",
    "        X_test.append(x_test)\n",
    "        Y_test.append(y_test)\n",
    "    return (X_train, Y_train, X_test, Y_test, norm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(26986, 73)\n",
      "50\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m (X_train, Y_train, X_test, Y_test, norm_params) \u001b[39m=\u001b[39m generate_merged_dataset()\n",
      "Cell \u001b[1;32mIn [3], line 6\u001b[0m, in \u001b[0;36mgenerate_merged_dataset\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m Y_test \u001b[39m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m pts \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39msub-\u001b[39m\u001b[39m%02d\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m%\u001b[39mi \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m11\u001b[39m)]\n\u001b[1;32m----> 6\u001b[0m (X_train, Y_train, x_test, y_test, mu_input, std_input, mu_output, std_output) \u001b[39m=\u001b[39m generate_datasets(pts[\u001b[39m0\u001b[39;49m])\n\u001b[0;32m      7\u001b[0m norm_params[\u001b[39mstr\u001b[39m(\u001b[39m0\u001b[39m)]\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mmu_input\u001b[39m\u001b[39m'\u001b[39m:mu_input, \u001b[39m'\u001b[39m\u001b[39mstd_input\u001b[39m\u001b[39m'\u001b[39m:std_input, \u001b[39m'\u001b[39m\u001b[39mmu_output\u001b[39m\u001b[39m'\u001b[39m:mu_output, \u001b[39m'\u001b[39m\u001b[39mstd_output\u001b[39m\u001b[39m'\u001b[39m:std_output}\n\u001b[0;32m      8\u001b[0m X_test\u001b[39m.\u001b[39mappend(x_test)\n",
      "Cell \u001b[1;32mIn [11], line 26\u001b[0m, in \u001b[0;36mgenerate_datasets\u001b[1;34m(pt, feat_path)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mprint\u001b[39m(shape1)\n\u001b[0;32m     25\u001b[0m train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mshuffle(train)\n\u001b[1;32m---> 26\u001b[0m X_train \u001b[39m=\u001b[39m train[:, :shape1]\n\u001b[0;32m     27\u001b[0m Y_train \u001b[39m=\u001b[39m train[:, shape1:]\n\u001b[0;32m     29\u001b[0m \u001b[39m# Standardize input\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "(X_train, Y_train, X_test, Y_test, norm_params) = generate_merged_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create FC-DNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fndnn(input_dim, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=60, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=30, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=output_dim, activation='linear'))\n",
    "\n",
    "    optimizer=Adam(learning_rate=0.001)\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.99539, saving model to fcdnn.hdf5\n",
      "1888/1888 - 6s - loss: 1.0249 - mae: 0.7813 - val_loss: 0.9954 - val_mae: 0.6538 - 6s/epoch - 3ms/step\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m checkpointer\u001b[39m=\u001b[39mModelCheckpoint(filepath\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfcdnn.hdf5\u001b[39m\u001b[39m'\u001b[39m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      7\u001b[0m model \u001b[39m=\u001b[39m create_fndnn(input_dim\u001b[39m=\u001b[39mX_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], output_dim\u001b[39m=\u001b[39mY_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n\u001b[1;32m----> 9\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, Y_train, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m, epochs\u001b[39m=\u001b[39;49mepochs, batch_size\u001b[39m=\u001b[39;49mbatch_size, verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[checkpointer, early_stopping])\n",
      "File \u001b[1;32me:\\MateSzecsi\\Egyetem\\neuralis_halok_a_gyakban\\NagyHFProd\\BRAIN2SPEECH\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32me:\\MateSzecsi\\Egyetem\\neuralis_halok_a_gyakban\\NagyHFProd\\BRAIN2SPEECH\\.venv\\lib\\site-packages\\keras\\engine\\training.py:1555\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1551\u001b[0m \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m   1552\u001b[0m     data_handler\u001b[39m.\u001b[39m_initial_step \u001b[39m=\u001b[39m data_handler\u001b[39m.\u001b[39m_initial_step \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   1553\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_load_initial_step_from_ckpt()\n\u001b[0;32m   1554\u001b[0m     )\n\u001b[1;32m-> 1555\u001b[0m     \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[0;32m   1556\u001b[0m         \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m             epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m             _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m         ):\n\u001b[0;32m   1563\u001b[0m             callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[1;32me:\\MateSzecsi\\Egyetem\\neuralis_halok_a_gyakban\\NagyHFProd\\BRAIN2SPEECH\\.venv\\lib\\site-packages\\keras\\engine\\data_adapter.py:1374\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insufficient_data:  \u001b[39m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[0;32m   1373\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> 1374\u001b[0m original_spe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution\u001b[39m.\u001b[39;49mnumpy()\u001b[39m.\u001b[39mitem()\n\u001b[0;32m   1375\u001b[0m can_run_full_execution \u001b[39m=\u001b[39m (\n\u001b[0;32m   1376\u001b[0m     original_spe \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1377\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1378\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m original_spe\n\u001b[0;32m   1379\u001b[0m )\n\u001b[0;32m   1381\u001b[0m \u001b[39mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[1;32me:\\MateSzecsi\\Egyetem\\neuralis_halok_a_gyakban\\NagyHFProd\\BRAIN2SPEECH\\.venv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:637\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnumpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    636\u001b[0m   \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 637\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_value()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m    638\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    639\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\MateSzecsi\\Egyetem\\neuralis_halok_a_gyakban\\NagyHFProd\\BRAIN2SPEECH\\.venv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:728\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    725\u001b[0m   value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_variable_op()\n\u001b[0;32m    726\u001b[0m \u001b[39m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[39m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[1;32m--> 728\u001b[0m \u001b[39mreturn\u001b[39;00m array_ops\u001b[39m.\u001b[39;49midentity(value)\n",
      "File \u001b[1;32me:\\MateSzecsi\\Egyetem\\neuralis_halok_a_gyakban\\NagyHFProd\\BRAIN2SPEECH\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32me:\\MateSzecsi\\Egyetem\\neuralis_halok_a_gyakban\\NagyHFProd\\BRAIN2SPEECH\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32me:\\MateSzecsi\\Egyetem\\neuralis_halok_a_gyakban\\NagyHFProd\\BRAIN2SPEECH\\.venv\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:294\u001b[0m, in \u001b[0;36midentity\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39minput\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mgraph\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    291\u001b[0m   \u001b[39m# Make sure we get an input with handle data attached from resource\u001b[39;00m\n\u001b[0;32m    292\u001b[0m   \u001b[39m# variables. Variables have correct handle data when graph building.\u001b[39;00m\n\u001b[0;32m    293\u001b[0m   \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(\u001b[39minput\u001b[39m)\n\u001b[1;32m--> 294\u001b[0m ret \u001b[39m=\u001b[39m gen_array_ops\u001b[39m.\u001b[39;49midentity(\u001b[39minput\u001b[39;49m, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m    295\u001b[0m \u001b[39m# Propagate handle data for happier shape inference for resource variables.\u001b[39;00m\n\u001b[0;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39minput\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_handle_data\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32me:\\MateSzecsi\\Egyetem\\neuralis_halok_a_gyakban\\NagyHFProd\\BRAIN2SPEECH\\.venv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:4068\u001b[0m, in \u001b[0;36midentity\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m   4066\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   4067\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 4068\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   4069\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mIdentity\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, \u001b[39minput\u001b[39;49m)\n\u001b[0;32m   4070\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   4071\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "batch_size = 128\n",
    "\n",
    "early_stopping=EarlyStopping(patience=5, verbose=1)\n",
    "checkpointer=ModelCheckpoint(filepath='fcdnn.hdf5', save_best_only=True, verbose=1)\n",
    "\n",
    "model = create_fndnn(input_dim=X_train.shape[1], output_dim=Y_train.shape[1])\n",
    "\n",
    "history = model.fit(X_train, Y_train, validation_split=0.1, epochs=epochs, batch_size=batch_size, verbose=2, callbacks=[checkpointer, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, X_test, Y_test, norm_params):\n",
    "    preds = []\n",
    "    spectograms = []\n",
    "    losses = []\n",
    "    for i in range(10):\n",
    "        y_pred = model.predict(X_test[i])\n",
    "        losses.append(mean_absolute_error(Y_test[i], y_pred))\n",
    "        preds.append(y_pred * norm_params[str(i)]['std_output'] + norm_params[str(i)]['mu_output'])\n",
    "        spectograms.append(Y_test[i] * norm_params[str(i)]['std_output'] + norm_params[str(i)]['mu_output'])\n",
    "    mae = np.sum(losses)\n",
    "    print('Mean absolute error of test set:{mae}')\n",
    "    return preds, spectograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viz spectrograms\n",
    "def visualize_results(preds, spectograms):\n",
    "\n",
    "    cm='viridis'\n",
    "    fig, ax = plt.subplots(2, sharex=True)\n",
    "\n",
    "    for i in range(10):\n",
    "        #Plot spectrograms\n",
    "        ax[0].imshow(np.flipud(spectograms[i].T), cmap=cm, interpolation=None,aspect='auto')\n",
    "        ax[0].set_ylabel('Log Mel-Spec Bin')\n",
    "        ax[1].imshow(np.flipud(preds[i].T), cmap=cm, interpolation=None,aspect='auto')\n",
    "        ax[1].set_ylabel('Log Mel-Spec Bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthesize audio files\n",
    "def synthesize_audio(preds, spectograms):\n",
    "    \n",
    "    result_path = 'dnn_results'\n",
    "    winLength = 0.05\n",
    "    frameshift = 0.01\n",
    "    audiosr = 16000\n",
    "    if not os.path.isdir(result_path):\n",
    "        os.makedirs(result_path)\n",
    "    for i in range(10):\n",
    "        #Synthesize waveform from spectrogram using Griffin-Lim\n",
    "        reconstructedWav = createAudio(preds[i],audiosr=audiosr,winLength=winLength,frameshift=frameshift)\n",
    "        wavfile.write(os.path.join(result_path,f'{i+1}_predicted.wav'),int(audiosr),reconstructedWav)\n",
    "\n",
    "        #For comparison synthesize the original spectrogram with Griffin-Lim\n",
    "        origWav = createAudio(spectograms[i],audiosr=audiosr,winLength=winLength,frameshift=frameshift)\n",
    "        wavfile.write(os.path.join(result_path,f'{i+1}_orig_synthesized.wav'),int(audiosr),origWav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "89/89 [==============================] - 0s 1ms/step\n",
      "Mean absolute error of test set:{mae}\n"
     ]
    }
   ],
   "source": [
    "preds, spectograms = test_model(model, X_test, Y_test, norm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_results(preds=preds, spectograms=spectograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesize_audio(preds=preds, spectograms=spectograms)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "cc66402ee9dd0d45cb681ef7bf9287b06b34cc512cacd28107dca7ce0d1247ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
